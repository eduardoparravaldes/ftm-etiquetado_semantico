--------------------------------------------
Installing Java
--------------------------------------------

Before installing Kafka, you will need to install Java on your system. You can install Oracle JDK 8 using the Webupd8 team PPA repository.

To add the repository, run the following command:

sudo add-apt-repository -y ppa:webupd8team/java

Next, update the metadata of the new repository by running the following command:

sudo apt-get update

Once you have finished, run the following command to install JDK 8:

sudo apt-get install oracle-java8-installer -y

You can also verify that JDK 8 is installed properly by running the following command:
sudo java -version

You should see the output something like this:

java version "1.8.0_66"
Java(TM) SE Runtime Environment (build 1.8.0_66-b17)
Java HotSpot(TM) 64-Bit Server VM (build 25.66-b17, mixed mode)




---------------------------------------------------

Download and Install Kafka  and  zookeeper

---------------------------------------------------

sudo apt-get install zookeeperd

Once installation is finished, it will be started as a daemon automatically. By default ZooKeeper will run on port 2181.

You can test it by running the following command:

netstat -ant | grep :2181

Now that Java and ZooKeeper are installed, it is time to download and extract Kafka from Apache website. You can use wget to download Kafka:
sudo wget http://ftp.cixug.es/apache/kafka/1.0.0/kafka_2.11-1.0.0.tgz

create a directory for Kafka installation:
sudo mkdir /opt/Kafka

download and extract Kafka from Apache website. You can use wget to download Kafka:
sudo tar -xvf kafka_2.11-1.0.0.tgz -C /opt/Kafka/

Start  Kafka
The next step is to start Kafka server, you can start it by running kafka-server-start.sh script 

sudo  /opt/Kafka/kafka_2.11-1.0.0/bin/kafka-server-start.sh /opt/Kafka/kafka_2.11-1.0.0/config/server.properties 

create a sample topic with name "testing"
sudo /opt/Kafka/kafka_2.11-1.0.0/bin/kafka-topics.sh  --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic testing

List topics
sudo /opt/Kafka/kafka_2.11-1.0.0/bin/kafka-topics.sh --list --zookeeper localhost:2181

Testing

Publicamos mensaje de prueba en el topic  con el producer
sudo /opt/Kafka/kafka_2.11-1.0.0/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic testing

Consumers
sudo /opt/Kafka/kafka_2.11-1.0.0/bin/kafka-console-consumer.sh  --zookeeper localhost:2181 --topic testing --from-beginning

sudo /opt/Kafka/kafka_2.11-1.0.0/bin/kafka-console-consumer.sh  --zookeeper localhost:2181 --topic palabra --from-beginning

Referencias: 
https://devops.profitbricks.com/tutorials/install-and-configure-apache-kafka-on-ubuntu-1604-1/
http://kafka.apache.org/documentation.html#streams

---------------------------------------------------

Download and Install python - spark - pyspark

---------------------------------------------------
Before installing pySpark, you must have Python and Spark installed.
Go to the Python official website to install it.

To install Spark, make sure you have Java 8 or higher installed on your computer. Then, visit the Spark downloads page. 
Select the latest Spark release, a prebuilt package for Hadoop, and download it directly.

Download Apache Spark from http://spark.apache.org/downloads.html
spark-2.3.0-bin-hadoop2.7
sudo tar xvzf spark-2.3.0-bin-hadoop2.7.tgz -C /usr/local

Let's modify ~/.bashrc:

export SPARK_HOME=/usr/local/spark-2.3.0-bin-hadoop2.7
export PATH=$SPARK_HOME/bin:$PATH

-------------------------------
PySpark with Jupyter
-------------------------------
If Jupyter not installed, please visit Ipython and Jupyter Notebook Install via Pip.

#Install Ipython:
sudo apt-get -y install ipython ipython-notebook

#Install Jupyter:
sudo -H pip install jupyter

sudo -H pip install --upgrade pip

sudo -H pip install jupyter

#Running Jupyter
jupyter notebook

#After install Jupyter, we need to add the following in ~/.bashrc:
export PYSPARK_DRIVER_PYTHON=/usr/local/bin/jupyter
export PYSPARK_DRIVER_PYTHON_OPTS="notebook --NotebookApp.open_browser=False --NotebookApp.ip='*' --NotebookApp.port=8880"
export PYSPARK_PYTHON=/usr/bin/python

#Next, fire up Jupyter:
pyspark

Referencias:
http://www.bogotobogo.com/Hadoop/BigData_hadoop_Apache_Spark_PySpark.php
http://www.bogotobogo.com/python/IPython/IPython_Jupyter_Install_iPython_Notebook_Matplotlib_Publishing_it_to_Github.php#Jupyter-Install-pip
https://www.python.org/

----------------------------------------------
Download and Install ElasticSearch - Kibana
-----------------------------------------------
https://www.elastic.co/guide/en/elasticsearch/reference/6.2/deb.html#deb-key
https://www.elastic.co/guide/en/kibana/6.2/deb.html


wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -

#You may need to install the apt-transport-https package on Debian before proceeding:

sudo apt-get install apt-transport-https

echo "deb https://artifacts.elastic.co/packages/6.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-6.x.list

sudo apt-get update && sudo apt-get install elasticsearch

sudo apt-get update && sudo apt-get install kibana

http://localhost:9200
http://localhost:5601/

